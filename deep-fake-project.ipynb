{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11202854,"sourceType":"datasetVersion","datasetId":6544494}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"39b58b5a-636c-4d7e-ab8b-62512c264e70","cell_type":"code","source":"pip install \"numpy<2.0\" ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T03:31:55.635989Z","iopub.execute_input":"2025-03-17T03:31:55.636297Z","iopub.status.idle":"2025-03-17T03:31:59.789216Z","shell.execute_reply.started":"2025-03-17T03:31:55.636274Z","shell.execute_reply":"2025-03-17T03:31:59.787804Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: numpy<2.0 in /usr/local/lib/python3.10/dist-packages (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2.0) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2.0) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2.0) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.0) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2.0) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2.0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2.0) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"id":"19e5ba52-4d8d-4478-9c92-121a1167e66e","cell_type":"code","source":"pip install mtcnn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-17T03:31:59.790533Z","iopub.execute_input":"2025-03-17T03:31:59.790776Z","iopub.status.idle":"2025-03-17T03:32:03.877089Z","shell.execute_reply.started":"2025-03-17T03:31:59.790755Z","shell.execute_reply":"2025-03-17T03:32:03.876179Z"}},"outputs":[{"name":"stdout","text":"Collecting mtcnn\n  Downloading mtcnn-1.0.0-py3-none-any.whl.metadata (5.8 kB)\nRequirement already satisfied: joblib>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from mtcnn) (1.4.2)\nCollecting lz4>=4.3.3 (from mtcnn)\n  Downloading lz4-4.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\nDownloading mtcnn-1.0.0-py3-none-any.whl (1.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading lz4-4.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: lz4, mtcnn\nSuccessfully installed lz4-4.4.3 mtcnn-1.0.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"id":"b3ae96a8-e5c6-4016-8413-d3681ddc30e8","cell_type":"code","source":"import cv2\nimport os\nimport keras\nimport shutil\nimport numpy as np\nfrom mtcnn import MTCNN\nimport tensorflow as tf\nimport matplotlib.pyplot as plt","metadata":{"scrolled":true,"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T14:37:15.271534Z","iopub.execute_input":"2025-03-29T14:37:15.271827Z","iopub.status.idle":"2025-03-29T14:37:15.275881Z","shell.execute_reply.started":"2025-03-29T14:37:15.271803Z","shell.execute_reply":"2025-03-29T14:37:15.274941Z"}},"outputs":[],"execution_count":2},{"id":"5b3754aa-4957-4668-a889-eb8bbca6e0b6","cell_type":"code","source":"path = 'Real_Data/Extracted/'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T08:29:29.458182Z","iopub.execute_input":"2025-03-29T08:29:29.458817Z","iopub.status.idle":"2025-03-29T08:29:29.462542Z","shell.execute_reply.started":"2025-03-29T08:29:29.458777Z","shell.execute_reply":"2025-03-29T08:29:29.461676Z"}},"outputs":[],"execution_count":2},{"id":"f4532399-e617-4b79-96d4-bc4c5c2620b3","cell_type":"code","source":"dir_ = os.listdir('./Real_Data/Extracted/')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"98dae8d9-4d27-4f4c-8703-d81242d346cf","cell_type":"code","source":"for i in dir_:\n    a = i + \"/video\"\n    print(os.listdir(path + i +'/video')[3:])","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","output_type":"stream","text":["['sa1', 'sa2', 'si1279', 'si1909', 'si649', 'sx109', 'sx19', 'sx199', 'sx289', 'sx379']\n","['sa1', 'sa2', 'si1573', 'si2203', 'si943', 'sx133', 'sx223', 'sx313', 'sx403', 'sx43']\n","['sa1', 'sa2', 'si1178', 'si1808', 'si548', 'sx188', 'sx278', 'sx368', 'sx8', 'sx98']\n","['sa1', 'sa2', 'si1454', 'si2084', 'si824', 'sx104', 'sx14', 'sx194', 'sx284', 'sx374']\n","['sa1', 'sa2', 'si1474', 'si2104', 'si844', 'sx124', 'sx214', 'sx304', 'sx34', 'sx394']\n","['sa1', 'sa2', 'si1544', 'si1566', 'si2149', 'sx104', 'sx14', 'sx194', 'sx284', 'sx374']\n","['sa1', 'sa2', 'si1084', 'si1653', 'si1714', 'sx184', 'sx274', 'sx364', 'sx4', 'sx94']\n","['sa1', 'sa2', 'si1386', 'si2016', 'si756', 'sx126', 'sx216', 'sx306', 'sx36', 'sx396']\n","['sa1', 'sa2', 'si1400', 'si2030', 'si770', 'sx140', 'sx230', 'sx320', 'sx410', 'sx50']\n","['sa1', 'sa2', 'si1264', 'si1894', 'si634', 'sx184', 'sx274', 'sx364', 'sx4', 'sx94']\n","['sa1', 'sa2', 'si1116', 'si1587', 'si1746', 'sx126', 'sx216', 'sx306', 'sx36', 'sx396']\n","['sa1', 'sa2', 'si1265', 'si635', 'si992', 'sx185', 'sx275', 'sx365', 'sx5', 'sx95']\n","['sa1', 'sa2', 'si1490', 'si2120', 'si860', 'sx140', 'sx230', 'sx320', 'sx410', 'sx50']\n","['sa1', 'sa2', 'si1360', 'si522', 'si730', 'sx10', 'sx100', 'sx190', 'sx280', 'sx370']\n","['sa1', 'sa2', 'si1469', 'si2099', 'si839', 'sx119', 'sx209', 'sx29', 'sx299', 'sx389']\n","['sa1', 'sa2', 'si1398', 'si2028', 'si768', 'sx138', 'sx228', 'sx318', 'sx408', 'sx48']\n","['sa1', 'sa2', 'si1039', 'si1669', 'si2299', 'sx139', 'sx229', 'sx319', 'sx409', 'sx49']\n","['sa1', 'sa2', 'si1825', 'si565', 'sx115', 'sx1195', 'sx205', 'sx25', 'sx295', 'sx385']\n","['sa1', 'sa2', 'si1543', 'si2173', 'si913', 'sx103', 'sx13', 'sx193', 'sx283', 'sx373']\n","['sa1', 'sa2', 'si1539', 'si2169', 'si909', 'sx189', 'sx279', 'sx369', 'sx9', 'sx99']\n","['sa1', 'sa2', 'si1988', 'si2247', 'si728', 'sx188', 'sx278', 'sx368', 'sx8', 'sx98']\n","['sa1', 'sa2', 'si1010', 'si1640', 'si2270', 'sx110', 'sx20', 'sx200', 'sx290', 'sx380']\n","['sa1', 'sa2', 'si2255', 'si995', 'sx1625', 'sx185', 'sx275', 'sx365', 'sx5', 'sx95']\n","['sa1', 'sa2', 'si1425', 'si1555', 'si2028', 'sx102', 'sx12', 'sx192', 'sx282', 'sx372']\n","['sa1', 'sa2', 'si1542', 'si2172', 'si912', 'sx102', 'sx12', 'sx192', 'sx282', 'sx372']\n","['sa1', 'sa2', 'si1099', 'si1729', 'si469', 'sx109', 'sx19', 'sx199', 'sx289', 'sx379']\n","['sa1', 'sa2', 'si1541', 'si2171', 'si911', 'sx101', 'sx11', 'sx191', 'sx281', 'sx371']\n","['sa1', 'sa2', 'si1199', 'si1829', 'si569', 'sx119', 'sx209', 'sx29', 'sx299', 'sx389']\n","['sa1', 'sa2', 'si1364', 'si1624', 'si734', 'sx104', 'sx14', 'sx194', 'sx284', 'sx374']\n","['sa1', 'sa2', 'si1899', 'si639', 'si869', 'sx189', 'sx279', 'sx369', 'sx9', 'sx99']\n","['sa1', 'sa2', 'si1024', 'si2222', 'si2284', 'sx124', 'sx214', 'sx304', 'sx34', 'sx394']\n","['sa1', 'sa2', 'si1553', 'si2183', 'si923', 'sx113', 'sx203', 'sx23', 'sx293', 'sx383']\n"]}],"execution_count":39},{"id":"3c4d3448-8d07-46bc-883c-8eb041136dd6","cell_type":"code","source":"for i in os.listdir('Real_Data/Extracted/fadg0/video/sa1'):\n    name = i + '.jpg'\n    os.rename(path + i, name)","metadata":{},"outputs":[],"execution_count":18},{"id":"b98347f5-8196-4321-b0dd-a46ef78234ca","cell_type":"code","source":"subject_ids = os.listdir(path)","metadata":{},"outputs":[],"execution_count":37},{"id":"ba3dd729-438d-40bc-9755-91ae0fda226b","cell_type":"code","source":"subject_ids","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"8ad1c548-34df-4f04-9daf-3460424f5088","cell_type":"code","source":"for subject in subject_ids:\n    new_path = path + subject + '/video/'\n    categories = os.listdir(new_path)[3:]\n    for cat in categories:\n        frames = os.listdir(new_path + cat)\n        for frame in frames:\n            frame_path = new_path + cat + '/'\n            os.rename(frame_path + frame, frame_path+frame + '.jpg')","metadata":{},"outputs":[],"execution_count":40},{"id":"4068dfb7-b1a1-400b-87e6-59be896b93fb","cell_type":"code","source":"# Function to convert the frames to a video\n\ndef write_video_from_frames(frame_folder, output_video_path, fps=30):\n    images = sorted(os.listdir(frame_folder))\n    first_frame = cv2.imread(os.path.join(frame_folder, images[0]))\n\n    if first_frame is None:\n        raise ValueError(\"No valid frames found!\")\n\n    height, width, _ = first_frame.shape\n\n\n    fourcc = cv2.VideoWriter_fourcc(*'mp4v') \n    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n\n    for image in images:\n        frame = cv2.imread(os.path.join(frame_folder, image))\n        if frame is not None:\n            out.write(frame)  \n\n    out.release()\n    print(f\"Video saved at: {output_video_path}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"4773dd16-34d7-4952-ab8f-29a22bf8d855","cell_type":"code","source":"real_dir = os.listdir(\"./Real_Data/Extracted/\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"9965840b-f13e-45f1-8615-95fe1280c45a","cell_type":"code","source":"path = \"./Real_Data/Extracted/\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"b5fd991e-b808-4aca-93b0-30bb978d2548","cell_type":"code","source":"for subject in real_dir:\n    os.makedirs('./Real_Data_Video/' + subject, exist_ok=True)\n    sub_path = path + subject + '/video/'\n    for category in os.listdir(sub_path)[3:]:\n        category_path = './Real_Data_Video/' + subject + '/' + category\n        write_video_from_frames(sub_path + category,category_path+\".mp4\",fps=25)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"000105aa-350f-4c1a-a413-b81114d77490","cell_type":"markdown","source":"\n## ***Detecting Cordinates Of Face In Each Frame By MTCNN and Converting Videos Of Fake Dataset Into Compressed .npz***","metadata":{}},{"id":"f76afcd8-3b1a-4021-8c93-5463e6c6d5f0","cell_type":"code","source":"fake_data_dir = os.listdir('Fake_Data/higher_quality')","metadata":{},"outputs":[],"execution_count":7},{"id":"38b585eb-95a9-417d-8a12-9c37b2fda540","cell_type":"code","source":"path = 'Fake_Data/higher_quality/'","metadata":{},"outputs":[],"execution_count":8},{"id":"e6e950d7-c7e1-4274-a80d-2ebdded6cdc0","cell_type":"code","source":"detector = MTCNN()","metadata":{},"outputs":[],"execution_count":4},{"id":"f9c3847d-1cb0-40ab-8dac-e1834b70c690","cell_type":"code","source":"# Reading a video frame by frame and detecting cordinates of the face. Returning a numpy array of size (Total number of frames,244,244,3)\n\ndef video_to_numpy(path):\n    detector = MTCNN(device = \"GPU:0\")\n    array_list = []\n    cap = cv2.VideoCapture(path)\n    if cap.isOpened() == False:\n        raise RuntimeError\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n    \n        if ret:\n            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n            face = detector.detect_faces(frame)\n            if not face :\n                continue\n            col_1, row_1, col_2, row_2 = face[0]['box']\n            col_1_, row_1_, col_2_, row_2_ = col_1, row_1, col_2 + col_1, row_2 + row_1\n            frame = frame[row_1_ : row_2_, col_1_ : col_2_]\n            \n            if frame is None or frame.size == 0:\n                continue\n                \n            frame = cv2.resize(frame, dsize = (224,224))\n            array_list.append(frame)\n    \n        else: \n            break\n\n    cap.release()\n            \n    return np.array(array_list)","metadata":{},"outputs":[],"execution_count":45},{"id":"44db9ce2-6732-4799-a53d-019b2152daa0","cell_type":"code","source":"real_data_dir = os.listdir('Real_Data_Video')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"f49543c7-4976-408d-9f19-2e3521586bb7","cell_type":"code","source":"path = 'Real_Data_Video/'","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"825938d4-5307-4e99-a33a-c7342f45f04d","cell_type":"code","source":"for subject in real_data_dir:\n    \n    os.makedirs('./Real_Data_Video_Numpy/'+ subject, exist_ok=True)\n    sub_path = path + subject\n\n    for video in os.listdir(sub_path):\n        array = video_to_numpy(sub_path + '/' + video)\n        video_path = \"./Real_Data_Video_Numpy/\"+ subject + '/' + video\n        np.savez_compressed(video_path, array)\n        print(video_path)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"8c419b61-f991-4215-bd09-f5951dcdb28b","cell_type":"code","source":"for subject in fake_data_dir[9:]:\n    \n    os.makedirs('./Fake_Data_Numpy/'+ subject, exist_ok=True)\n    sub_path = path + subject\n\n    for video in os.listdir(sub_path):\n        if video.endswith('.avi'):\n            array = video_to_numpy(sub_path + '/' + video)\n            video_path = './Fake_Data_Numpy/'+ subject + '/' + video.split(sep = '-')[0]\n            np.savez_compressed(video_path, array)\n            print(video_path)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"2df2abf6-6bd5-42e5-b014-21af2308c2e8","cell_type":"markdown","source":"## ***Model building and training***","metadata":{}},{"id":"9dd2f836-f003-44e5-9e2a-3ef3461315e5","cell_type":"code","source":"def data_gen(fake_list, real_list, batch_size, frame_threshold,type_):\n\n    '''fake_list : list of paths of the videos in the fake data directory\n        real_list : list of paths of the videos in the real data directory\n        batch_size : integer, number of videos to be fetch\n        frame_threshold : integer, number of frames to keep in all videos. Padding will be done automatically\n        \n        Return: return a tuple (data, labels)'''\n\n    num_videos = len(fake_list)\n    real_data_index = np.random.permutation(np.arange(0,num_videos))\n    fake_data_index = np.random.permutation(np.arange(0,num_videos))\n    count = 0\n    \n    rnet = keras.applications.ResNet50(include_top = False, weights = 'imagenet')\n    preprocess = keras.applications.resnet.preprocess_input\n        \n    while True:\n\n        fake_data_array = np.zeros(shape = (batch_size//2,frame_threshold,7,7,2048))\n        real_data_array = np.zeros(shape = (batch_size//2, frame_threshold, 7,7,2048))\n\n        fake_labels = np.ones(shape = batch_size//2, dtype = int)\n        real_labels = np.zeros(shape = batch_size//2, dtype = int)\n        \n        for i in range(batch_size//2):\n            \n\n            fake_array = np.load(fake_list[fake_data_index[count]])['arr_0']\n            real_array = np.load(real_list[real_data_index[count]])['arr_0']\n\n\n            # Keeping the number of frames to be same by either slicing the video or adding padding to the video\n\n            if fake_array.shape[0] < frame_threshold: # Padding to fake video\n                remaining_frames = frame_threshold - fake_array.shape[0]             \n                fake_array = np.concatenate([fake_array,np.zeros(shape = (remaining_frames,224,224,3))], axis = 0)\n\n            if fake_array.shape[0] > frame_threshold: # slicing the fake video\n                fake_array = fake_array[:frame_threshold]\n\n            if real_array.shape[0] < frame_threshold: # Padding to real video\n                remaining_frames = frame_threshold - real_array.shape[0]\n                real_array = np.concatenate([real_array,np.zeros(shape = (remaining_frames,224,224,3))], axis = 0)\n\n            if real_array.shape[0] > frame_threshold: # slicing the real video\n                real_array = real_array[:frame_threshold]\n\n            fake_data_array[i] = rnet.predict(preprocess(fake_array), verbose = False)\n            real_data_array[i] = rnet.predict(preprocess(real_array),verbose = False)\n                \n\n            count = count + 1\n        \n            if abs(count - real_data_index.shape[0]) < batch_size:\n                \n                real_data_index = np.random.permutation(np.arange(0,num_videos))\n                fake_data_index = np.random.permutation(np.arange(0,num_videos))\n                \n                count = 0\n\n        data_array = np.concatenate([fake_data_array, real_data_array], axis = 0)\n        label_array = np.concatenate([fake_labels, real_labels])\n        # index = np.random.permutation(range(batch_size))\n        yield (data_array, label_array)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T13:17:27.981355Z","iopub.execute_input":"2025-03-26T13:17:27.981844Z","iopub.status.idle":"2025-03-26T13:17:27.990669Z","shell.execute_reply.started":"2025-03-26T13:17:27.981820Z","shell.execute_reply":"2025-03-26T13:17:27.989889Z"}},"outputs":[],"execution_count":4},{"id":"095f9e39-60fd-4353-b884-83a1b39c3606","cell_type":"code","source":"import gc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-26T13:17:28.027325Z","iopub.execute_input":"2025-03-26T13:17:28.027632Z","iopub.status.idle":"2025-03-26T13:17:28.043406Z","shell.execute_reply.started":"2025-03-26T13:17:28.027594Z","shell.execute_reply":"2025-03-26T13:17:28.042811Z"}},"outputs":[],"execution_count":6},{"id":"af7de6dd-4005-4c03-ae5f-fa029aab3b09","cell_type":"code","source":"import gc\ndef data_gen(fake_list, real_list, batch_size, frame_threshold,type_, shuffle = True):\n\n    '''fake_list : list of paths of the videos in the fake data directory\n        real_list : list of paths of the videos in the real data directory\n        batch_size : integer, number of videos to be fetch. When using it for validation gen, then choose the size such that it compleatly divides the total number of videos in one validation set\n        frame_threshold : integer, number of frames to keep in all videos. Padding will be done automatically\n        shuffle : Default (Shuffle = True), Used to shuffle the dataset in each epoch. For the validation generator, shuffle == False, provides better generalization results.\n        \n        Return: return a tuple (data, labels)'''\n    \n    mix_data = np.concatenate((fake_list, real_list))\n    labels = np.concatenate((np.zeros(shape=(fake_list.shape[0])), np.ones(shape = (real_list.shape[0])))).astype(np.float32)\n    num_videos = len(fake_list) * 2\n    mix_data_index = np.random.permutation(np.arange(0,num_videos))\n    count = 0\n    \n    rnet = keras.applications.ResNet50(include_top = False, weights = 'imagenet')\n    preprocess = keras.applications.resnet.preprocess_input\n        \n    while True:\n        mix_data_array = tf.Variable(tf.zeros(shape = (batch_size,frame_threshold,7,7,2048)))\n        mix_labels =  tf.Variable(tf.zeros(shape = (batch_size,)))\n\n        for i in range(batch_size):\n\n            mix_array = np.load(mix_data[mix_data_index[count]])['arr_0']\n\n\n\n            if mix_array.shape[0] < frame_threshold: # Adding reaming frames to video\n                remaining_frames = frame_threshold - mix_array.shape[0]             \n                mix_array = np.concatenate([mix_array,np.zeros(shape = (remaining_frames,224,224,3))], axis = 0)\n\n            if mix_array.shape[0] > frame_threshold: # Slicing the extra frames from the video\n                mix_array = mix_array[:frame_threshold]\n\n\n            mix_data_array[i].assign(tf.constant(rnet.predict(preprocess(mix_array), verbose = False)))\n            mix_labels[i].assign(tf.constant(labels[mix_data_index[count]]))\n                \n\n            count = count + 1\n        \n        if (abs(count - mix_data_index.shape[0]) < batch_size) & (shuffle == False):\n            \n            count = 0\n            gc.collect()\n\n        elif (abs(count - mix_data_index.shape[0]) < batch_size) & (shuffle == True):\n            \n            mix_data_index = np.random.permutation(np.arange(0,num_videos))\n            count = 0\n            gc.collect()\n\n                \n\n        yield (mix_data_array, mix_labels)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T14:37:20.788935Z","iopub.execute_input":"2025-03-29T14:37:20.789274Z","iopub.status.idle":"2025-03-29T14:37:20.798292Z","shell.execute_reply.started":"2025-03-29T14:37:20.789245Z","shell.execute_reply":"2025-03-29T14:37:20.797222Z"}},"outputs":[],"execution_count":3},{"id":"0a581c1e-3a88-4819-80b7-74332913c144","cell_type":"code","source":"fake_data_array = np.array([], dtype = 'object')\nfor i,j,k in os.walk('/kaggle/input/timit-fake-real-dataset-numpy/Fake_Data_Numpy'):\n    temp = i + '/' + np.array(k, dtype = 'object')\n    fake_data_array = np.append(fake_data_array,temp)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T14:37:21.061677Z","iopub.execute_input":"2025-03-29T14:37:21.061966Z","iopub.status.idle":"2025-03-29T14:37:21.271117Z","shell.execute_reply.started":"2025-03-29T14:37:21.061943Z","shell.execute_reply":"2025-03-29T14:37:21.269372Z"}},"outputs":[],"execution_count":4},{"id":"8869dff9-db3b-4c8a-a4ef-2c062553c275","cell_type":"code","source":"real_data_array = np.array([], dtype = 'object')\nfor i,j,k in os.walk('/kaggle/input/timit-fake-real-dataset-numpy/Real_Data_Numpy/'):\n    temp = i + '/' + np.array(k, dtype = 'object')\n    real_data_array = np.append(real_data_array,temp)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T14:37:22.516569Z","iopub.execute_input":"2025-03-29T14:37:22.516869Z","iopub.status.idle":"2025-03-29T14:37:22.709067Z","shell.execute_reply.started":"2025-03-29T14:37:22.516845Z","shell.execute_reply":"2025-03-29T14:37:22.708433Z"}},"outputs":[],"execution_count":5},{"id":"53331417-0ba8-4d77-8dbc-0d823384c9b2","cell_type":"code","source":"batch_size = 4\nn_frame = 80","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T14:37:22.726787Z","iopub.execute_input":"2025-03-29T14:37:22.726992Z","iopub.status.idle":"2025-03-29T14:37:22.730147Z","shell.execute_reply.started":"2025-03-29T14:37:22.726973Z","shell.execute_reply":"2025-03-29T14:37:22.729404Z"}},"outputs":[],"execution_count":6},{"id":"4ea9f8d5-d86c-4067-8924-0d50454a0014","cell_type":"code","source":"l2 = keras.regularizers.l2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T14:37:22.938254Z","iopub.execute_input":"2025-03-29T14:37:22.938525Z","iopub.status.idle":"2025-03-29T14:37:22.941962Z","shell.execute_reply.started":"2025-03-29T14:37:22.938492Z","shell.execute_reply":"2025-03-29T14:37:22.941143Z"}},"outputs":[],"execution_count":7},{"id":"c68fc23d-35a9-4cd6-9dec-36e3c4b7d019","cell_type":"code","source":"training_size = int(fake_data_array.shape[0]  * 0.8)\nvalidation_size = int(fake_data_array.shape[0] * 0.2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T14:37:23.111564Z","iopub.execute_input":"2025-03-29T14:37:23.111784Z","iopub.status.idle":"2025-03-29T14:37:23.115402Z","shell.execute_reply.started":"2025-03-29T14:37:23.111764Z","shell.execute_reply":"2025-03-29T14:37:23.114596Z"}},"outputs":[],"execution_count":8},{"id":"fc9b453d-bc90-4e7d-b9c8-89a027367b8d","cell_type":"code","source":"training_gen = data_gen(fake_data_array[:training_size], real_data_array[:training_size],batch_size,n_frame,type_='training')\nvalidation_gen = data_gen(fake_data_array[training_size : training_size + validation_size], real_data_array[training_size : training_size + validation_size], batch_size, n_frame, type_ = 'val',shuffle =False )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T14:37:23.341873Z","iopub.execute_input":"2025-03-29T14:37:23.342080Z","iopub.status.idle":"2025-03-29T14:37:23.345768Z","shell.execute_reply.started":"2025-03-29T14:37:23.342062Z","shell.execute_reply":"2025-03-29T14:37:23.345014Z"}},"outputs":[],"execution_count":9},{"id":"3db7db92-fd4b-4154-85e2-9d5897fa0577","cell_type":"code","source":"def network():\n    input_ = keras.layers.Input(shape = (n_frame, 7,7,2048))\n    \n    x = keras.layers.TimeDistributed(keras.layers.BatchNormalization())(input_)\n    x = keras.layers.TimeDistributed(keras.layers.Flatten())(x)\n    \n    x = keras.layers.LSTM(64, kernel_regularizer=l2(0.1))(x)\n    x = keras.layers.BatchNormalization()(x)\n    \n    x = keras.layers.Dense(units = 1,activation='sigmoid')(x) \n    \n    return keras.models.Model(input_, x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T09:01:59.683931Z","iopub.execute_input":"2025-03-29T09:01:59.684206Z","iopub.status.idle":"2025-03-29T09:01:59.688960Z","shell.execute_reply.started":"2025-03-29T09:01:59.684184Z","shell.execute_reply":"2025-03-29T09:01:59.688172Z"}},"outputs":[],"execution_count":9},{"id":"7d8a4594-5d70-46fa-816d-639c1e5aebfe","cell_type":"code","source":"model = network()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T09:02:00.903937Z","iopub.execute_input":"2025-03-29T09:02:00.904209Z","iopub.status.idle":"2025-03-29T09:02:03.090164Z","shell.execute_reply.started":"2025-03-29T09:02:00.904187Z","shell.execute_reply":"2025-03-29T09:02:03.089490Z"}},"outputs":[],"execution_count":10},{"id":"9c98f7d1-7c3e-4fb1-92b3-c8ccc8232f63","cell_type":"code","source":"adam = keras.optimizers.Adam(learning_rate=10**(-5))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T14:38:01.089931Z","iopub.execute_input":"2025-03-29T14:38:01.090266Z","iopub.status.idle":"2025-03-29T14:38:01.096524Z","shell.execute_reply.started":"2025-03-29T14:38:01.090238Z","shell.execute_reply":"2025-03-29T14:38:01.095434Z"}},"outputs":[],"execution_count":11},{"id":"221c7778-86c6-48f2-b7cb-bbf33c4008da","cell_type":"code","source":"model_c = keras.callbacks.ModelCheckpoint(\"/kaggle/working/model_final.keras\", monitor = 'val_accuracy', save_best_only = True)\nmodel = keras.models.load_model(\"/kaggle/working/model_final.keras\")\nmodel.compile(optimizer=adam, loss = 'binary_crossentropy', metrics=['accuracy'])\nmodel.fit(training_gen, epochs=10, steps_per_epoch=(training_size* 2)//batch_size, validation_data= validation_gen, validation_steps = 32, callbacks = [model_c])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T14:38:05.227327Z","iopub.execute_input":"2025-03-29T14:38:05.227637Z","iopub.status.idle":"2025-03-29T15:31:00.050837Z","shell.execute_reply.started":"2025-03-29T14:38:05.227610Z","shell.execute_reply":"2025-03-29T15:31:00.049984Z"}},"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nEpoch 1/10\n\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m441s\u001b[0m 3s/step - accuracy: 0.9074 - loss: 8.0405 - val_accuracy: 0.8281 - val_loss: 6.8366\nEpoch 2/10\n\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m346s\u001b[0m 3s/step - accuracy: 0.9104 - loss: 6.3627 - val_accuracy: 0.8828 - val_loss: 5.7691\nEpoch 3/10\n\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 3s/step - accuracy: 0.9330 - loss: 5.5020 - val_accuracy: 0.8750 - val_loss: 5.1768\nEpoch 4/10\n\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 3s/step - accuracy: 0.9419 - loss: 4.8935 - val_accuracy: 0.7812 - val_loss: 4.8201\nEpoch 5/10\n\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 2s/step - accuracy: 0.9433 - loss: 4.4649 - val_accuracy: 0.8438 - val_loss: 4.4107\nEpoch 6/10\n\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 2s/step - accuracy: 0.9547 - loss: 4.0536 - val_accuracy: 0.8906 - val_loss: 4.0075\nEpoch 7/10\n\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 2s/step - accuracy: 0.9300 - loss: 3.8442 - val_accuracy: 0.8516 - val_loss: 3.7646\nEpoch 8/10\n\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 2s/step - accuracy: 0.9050 - loss: 3.5879 - val_accuracy: 0.9062 - val_loss: 3.4578\nEpoch 9/10\n\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m289s\u001b[0m 2s/step - accuracy: 0.9084 - loss: 3.3949 - val_accuracy: 0.8359 - val_loss: 3.3712\nEpoch 10/10\n\u001b[1m128/128\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m291s\u001b[0m 2s/step - accuracy: 0.9205 - loss: 3.1776 - val_accuracy: 0.9297 - val_loss: 3.0534\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7b5ecc33bc10>"},"metadata":{}}],"execution_count":12},{"id":"0befa653-5b91-4a04-8b57-97a252f218b1","cell_type":"code","source":"model.save(\"/kaggle/working/model_2.keras\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-29T08:37:34.439434Z","iopub.status.idle":"2025-03-29T08:37:34.439771Z","shell.execute_reply":"2025-03-29T08:37:34.439614Z"}},"outputs":[],"execution_count":null}]}